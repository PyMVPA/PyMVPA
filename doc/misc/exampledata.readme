.. -*- mode: rst; fill-column: 78 -*-
.. ex: set sts=4 ts=4 sw=4 et tw=79:
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
  #
  #   See COPYING file distributed along with the PyMVPA package for the
  #   copyright and license terms.
  #
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###

.. index:: example fMRI dataset

.. _exampledata:

Example fMRI Dataset
====================

For an easy start with PyMVPA an `example fMRI dataset`_ is provided. This is a
single subject from a study published by :ref:`Haxby et al. (2001) <HGF+01>`.
This dataset has already been repeatedly reanalyzed since its first publication
(e.g.  :ref:`Hanson et al (2004) <HMH04>` and :ref:`O'Toole et al. (2005) <
OJA+05`).

.. note::

  The orginal authors of :ref:`Haxby et al. (2001) <HGF+01>` hold the copyright
  of this dataset and made it available under the terms of the `Creative Commons
  Attribution-Share Alike 3.0`_ license.

.. _Creative Commons Attribution-Share Alike 3.0: http://creativecommons.org/licenses/by-sa/3.0/

The subset of the dataset that is available here has been converted into the
NIfTI dataformat and is preprocessed to a degree that should allow people
without prior fMRI experience to perform meaningful analyses. Moreover, it
should not require further preprocessing with external tools.

All preprocessing has been performed using tools from FSL_. Specifically, the
4D fMRI timeseries has been skull-stripped and thresholded to zero-out
non-brain voxels (using a brain outline estimate significantly larger than the
brain, to prevent removal of edge voxels actually covering brain tissue). The
corresponding commandline call to BET was::

  bet bold bold_brain -F -f 0.5 -g 0

Afterwards the timeseries has been motion-corrected using MCFLIRT::

  mcflirt -in bold_brain -out bold_mc -plots

The following files are available in the `example fMRI dataset`_ download
(approx. 100 MB):

.. _example FMRI dataset: http://www.pymvpa.org/files/pymvpa_exampledata.tar.bz2

bold.nii.gz
  The motion-corrected and skull-stripped 4D timeseries (1452 volumes with
  40 x 64 x 64 voxels, corresponding to a voxel size of 3.5 x 3.75 x 3.75 mm
  and a volume repetition time of 2.5 seconds). The timeseries contains all
  12 runs of the original experiment, concatenated in a single file. Please
  note, that the timeseries signal is *not* detrended.

bold_mc.par
  The motion correction parameter output. This is a 6-column textfile with
  three rotation and three translation parameters respectively. This
  information can be used e.g. as additional regressors for :ref:`motion-aware
  timeseries detrending <motion-aware_detrending>`.

mask.nii.gz
  A binary mask with a conservative brain outline estimate, i.e. including
  some non-brain voxels to prevent the exclusion of brain tissue.

attributes_literal.txt
  A two-column text file with the stimulation condition and the corresponding
  experimental run for each volume in the timeseries image. The labels are given
  in literal form (e.g. 'face').

attributes.txt
  Similar to `attributes_literal.txt`, but with the condition labels encoded as
  integers. This file is only provided for earlier PyMVPA version, that could
  not handle :ref:`literal labels <faq_literal_labels>`.


Once downloaded and extracted (e.g. into a folder `data/`), the dataset can be
easily loaded like this:

  >>> from mvpa.misc.io.base import SampleAttributes
  >>> from mvpa.datasets.mri import fmri_dataset
  >>> attrs = SampleAttributes('data/attributes_literal.txt',
  ...                          literallabels=True)
  >>> ds = fmri_dataset(samples='data/bold.nii.gz',
  ...                   labels=attrs.labels,
  ...                   chunks=attrs.chunks,
  ...                   labels_map=True,
  ...                   mask='data/mask.nii.gz')

Note, that instead of specific import statements, it is usually
more convinient, but slower, to import all functionality from
PyMVPA at once with `from mvpa.suite import *` statement.

.. note::

   The dataset used in the :ref:`examples <chap_examples>` shipped with PyMVPA is
   actually a minimal version (posterior half of a single brain slice) of this
   full dataset. After appropriately adjusting the path, it is possible to run
   several of the examples on this full dataset.

.. _FSL: http://www.fmrib.ox.ac.uk/fsl
