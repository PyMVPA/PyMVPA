.. -*- mode: rst; fill-column: 78 -*-
.. ex: set sts=4 ts=4 sw=4 et tw=79:
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
  #
  #   See COPYING file distributed along with the PyMVPA package for the
  #   copyright and license terms.
  #
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###

.. _classifiers:

.. index:: classifier

***********
Classifiers
***********

PyMVPA includes a number of ready-to-use classifiers, which are
described in the following sections. All classifiers implement the
same, very simple interface. Each classifier object takes all relevant
parameters as arguments to its constructor. Once instantiated, the
classifier object's `train()` method can be called with some
dataset. This trains the classifier using *all* samples in the
respective dataset.

The major task for a classifier is to make predictions. Predictions are made
by calling the classifier's `predict()` method with one or multiple data
samples. `predict()` operates on pure sample data and not datasets, as in
some cases the true label for a sample might be totally unknown.

This examples demonstrates the typical daily life of a classifier.

  >>> import numpy as N
  >>> from mvpa.clfs.knn import kNN
  >>> from mvpa.datasets import Dataset
  >>> training = Dataset(samples=N.array(
  ...                                N.arange(100),ndmin=2, dtype='float').T,
  ...                    labels=[0] * 50 + [1] * 50)
  >>> rand100 = N.random.rand(10)*100
  >>> validation = Dataset(samples=N.array(rand100, ndmin=2, dtype='float').T,
  ...                      labels=[ int(i>50) for i in rand100 ])
  >>> clf = kNN(k=10)
  >>> clf.train(training)
  >>> N.mean(clf.predict(training.samples) == training.labels)
  1.0
  >>> N.mean(clf.predict(validation.samples) == validation.labels)
  1.0

Two datasets with 100 and 10 samples each are generated. Both datasets only
have one feature and the associated label is 0 if the feature value is below
50 or 1 otherwise. The larger dataset contains all integers in the interval
(0,100) and is used to train the classifier. The smaller is used as a
validation dataset, to check whether the classifier learned something that
generalizes well across samples not included in the training dataset. In this
case the validation dataset consists of 10 random floating point values in the
interval (0,100).

The classifier in this example is a k-Nearest-Neighbour_ classifier that makes
use of the 10 nearest neighbours of a data sample to make its predictions
(k=10). One can see that after the training the classifier performs optimally
on the training dataset as well as on the validation data samples.

The choice of the classifier in the above example is more or less arbitrary.
Any classifier in PyMVPA could be used in place of kNN. This demonstrates
another useful feature of PyMVPA's classifiers. Due to the high-level
abstraction and the simple interface, almost all classifiers can be combined
with most algorithms in PyMVPA. This makes it very easy to test different
classifiers on some dataset (see Fig. 1).

.. image:: pics/classifier_comparison_plot.png
   :width: 12cm
   :alt: Classifier comparison

A comparison of the behavior of different classifiers (k-Nearest-Neighbour,
linear SVM, logistic regression, ridge regression and SVM with radial basis
function kernel) on a simple classification problem. The code to generate
these figure can be found in the `pylab_2d.py` example in the :ref:`pylab2d`
section.


.. index:: states

Stateful objects
================

Before looking at the different classifiers in more detail, it is
important to mention another feature common to all of them. While
their interface is simple, classifiers are in no way limited to report
only predictions. All classifiers implement an additional interface:
the so-called Stateful_ interface.  Objects of any class that is
derived from Stateful_ have attributes (we refer to such attributes
as state variables), which are conditionally computed and stored by
PyMVPA. Such conditional storage and access is handy if a variable of
interest might consume a lot of memory or needs intensive computation,
and not needed in most (or in some) of the use cases.

For instance, the :class:`Classifier` class defines the `trained_labels`
state variable, which just stores the unique labels for which the
classifier was trained. Since `trained_labels` stores meaningful
information only for a trained classifier, attempt to access
'clf.trained_labels' before training would result in an error,

 >>> from mvpa.misc.exceptions import UnknownStateError
 >>> try:
 ...     untrained_clf = kNN()
 ...     labels = untrained_clf.trained_labels
 ... except UnknownStateError:
 ...     "Does not work"
 'Does not work'

since the classifier has not seen the
data yet and, thus, does not know the labels. In other words, it is
not yet in the state to know anything about the labels, hence the name
Stateful_. We will refer to instances of classes derived from
Stateful_ as 'stateful'.  Any state variable can be enabled or
disabled on per instance basis at any time of the execution.

.. _Stateful: api/mvpa.misc.state.ClassWithCollections-class.html
.. _StateCollection: api/mvpa.misc.state.StateCollection-class.html

To continue the last example, each classifier, or more precisely every
stateful object, can be asked to report existing state-related attributes:

  >>> list_with_verbose_explanations = clf.states.listing

'clf.states' is an instance of StateCollection_ class which is a container
for all state variables of the given class. Although values can be queried
or set (if state is enabled) operating directly on the stateful object

  >>> clf.trained_labels
  array([0, 1])

any other operation on the state (e.g. enabling, disabling) has to be carried
out through the StateCollection_ '.states'.

  >>> print clf.states
  states{trained_dataset predicting_time*+ training_confusion predictions*+...}
  >>> clf.states.enable('values')
  >>> print clf.states
  states{trained_dataset predicting_time*+ training_confusion predictions*+...}
  >>> clf.states.disable('values')

A string representation of the state collection mentioned above lists
all state variables present accompanied with 2 markers: '+' for an
enabled state variable, and '*' for a variable that stores some value
(but might have been disabled already and, therefore, would have no
'+' and attempts to reassign it would result in no action).

.. TODO: Refactor

By default all classifiers provide state variables `values`,
`predictions`. The latter is simply the set of predictions that was returned
by the last call to the objects `predict()` method. The former is heavily
classifier-specific. By convention the `values` key provides access to the
raw values that a classifier prediction is based on. Depending on the
classifier, this information might required significant resources when stored.
Therefore all states can be disabled or enabled (`states.disable()`,
`states.enable()`) and their current status can be queried like this:

  >>> clf.states.isActive('predictions')
  True
  >>> clf.states.isActive('values')
  False

States can be enabled or disabled during stateful object construction, if
`enable_states` or `disable_states` (or both) arguments, which store the list
of desired state variables names, passed to the object constructor. Keyword
'all' can be used to select all known states for that stateful object.


.. index:: error, classifier error, transfer error


.. _transfer_error:

Error Calculation
=================

The :class:`~mvpa.clfs.transerror.TransferError` class provides a convenient way to determine the transfer
error of a trained classifier on some validation dataset, i.e. the accuracy of
the classifier's predictions on a novel, independent dataset. A :class:`~mvpa.clfs.transerror.TransferError`
object is instanciated by passing a classifier object to the constructor.
Optionally a custom error function can be specified (see `errorfx` argument).

To compute the transfer error simply call the object with a validation dataset.
The computed error value is returned. :class:`~mvpa.clfs.transerror.TransferError` also supports a state
variable `confusion` that contains the full confusion matrix of the predictions
made on the validation dataset. The confusion matrix is disabled by default.

If the :class:`~mvpa.clfs.transerror.TransferError` object is called with an optional training dataset, the
contained classifier is first training using this dataset before predictions
on the validation dataset are made.

  >>> from mvpa.clfs.transerror import TransferError
  >>> clf = kNN(k=10)
  >>> terr = TransferError(clf)
  >>> terr(validation, training )
  0.0



.. index:: cross-validation
.. _cross-validation:

Cross-validated Transfer Error
------------------------------

Often one is not only interested in a single transfer error on one validation
or test dataset, but on a cross-validated estimate of the transfer error. A
popular method is the so-called leave-one-out cross-validation.

The :class:`~mvpa.algorithms.cvtranserror.CrossValidatedTransferError` class provides a simple way to compute such
measure. It utilizes a :class:`~mvpa.clfs.transerror.TransferError` object and a :class:`~mvpa.datasets.splitter.Splitter`. When called with
a :class:`~mvpa.datasets.base.Dataset` the splitter generates splits of the Dataset and the transfer error
for all splits is computed by training on one of the splitted datasets and
making predictions on the other. By default the mean of transfer errors is
returned (but the actual `combiner` function is customizable).

The following example shows the minimal code for a leave-one-out
cross-validation reusing the transfer error object from the previous example
and some :class:`~mvpa.datasets.base.Dataset` `data`.

  >>> # create some dataset
  >>> from mvpa.misc.data_generators import normalFeatureDataset
  >>> data = normalFeatureDataset(perlabel=50, nlabels=2,
  ...                             nfeatures=20, nonbogus_features=[3, 7],
  ...                             snr=3.0)
  >>> # now cross-validation
  >>> from mvpa.algorithms.cvtranserror import CrossValidatedTransferError
  >>> from mvpa.datasets.splitter import NFoldSplitter
  >>> cvterr = CrossValidatedTransferError(terr,
  ...                                      NFoldSplitter(cvtype=1))
  >>> error = cvterr(data)



Basic Supervised Learning Methods
=================================

PyMVPA provides a number of learning methods (i.e. classifiers or
regression algorithms) that can be plug into the various algorithms
that are also part of the framework. Most importantly they all can be
combined or enhanced with :ref:`metaclassifiers`.

.. index:: gaussian process regression, GPR

Gaussian Process Regression
---------------------------

(`Wikipedia entry about gaussian process regression`_).

.. _Wikipedia entry about gaussian process regression: http://en.wikipedia.org/wiki/Gaussian_process_regression


.. index:: k-nearest-neighbour, kNN

k-Nearest-Neighbour
-------------------

The kNN_ classifier makes predictions based on the labels of nearby samples.
It currently uses Euclidian distance to determine the nearest neighbours, but
future enhancements may include support for other kernels.

.. _kNN: api/mvpa.clfs.knn.kNN-class.html


.. index:: least angle regression, LARS

Least Angle Regression
----------------------

:ref:`Efron et al. (2004) <EHJ+04>`


.. index:: logistic regression, penalized logistic regression

Penalized Logistic Regression
-----------------------------

The penalized logistic regression (PLR_) is similar to the ridge in that it
has a penalty term, however, it is trained to predict a binary outcome by
means of the logistic function (`Wikipedia entry about logistic regression`_).

.. _Wikipedia entry about logistic regression: http://en.wikipedia.org/wiki/Logistic_regression
.. _PLR: api/mvpa.clfs.plr.PLR-class.html



.. index:: ridge regression

Ridge Regression
----------------

Ridge regression (aka Tikhonov regularization) is a variant of a linear regression
(`Wikipedia entry about ridge regression`_).

The ridge regression classifier (RidgeReg_) performs a simple linear regression
with a penalty parameter to help avoid over-fitting.  The regression inserts an
intercept term so that you do not have to center your data.

.. _Wikipedia entry about ridge regression: http://en.wikipedia.org/wiki/Ridge_regression
.. _RidgeReg: api/mvpa.clfs.ridge.RidgeReg-class.html


.. index:: sparse multinomial logistic regression, SMLR

Sparse Multinomial Logistic Regression
--------------------------------------

Sparse Multinomial Logistic Regression
(:ref:`Krishnapuram et al., 2005 <KCF+05>`) is a fast multi-class classifier
that can easily deal with high-dimensional problems (`research paper about
SMLR`_).  PyMVPA includes two implementations: one in pure Python and a faster
one that makes use of a C extension for the performance critical pieces of the
code.

.. _research paper about SMLR: http://www.cs.duke.edu/~amink/publications/manuscripts/hartemink05.pami.pdf


.. index:: support vector machine, SVM

Support Vector Machines
-----------------------

Support vector machine (:ref:`Vapnik, 1995 <Vap95>`) classifiers (and
regressions) are popular
since they can deal with very high dimensional problems (`Wikipedia
entry about SVM`_), while maintaining reasonable generalization performance.

The support vector machine classes provide a family of classifiers by wrapping
libsvm_ and Shogun_ libraries, with corresponding base classes libsvm.SVM_ and
sg.SVM_ accordingly. By default SVM class is bound to libsvm's implementation
if such is available (shogun otherwise).

While any SVM class provides a complete interface, the others child classes
make it easy to run some subset of standard classifiers, such as linear SVM,
with a default set of parameters (see LinearCSVMC_, LinearNuSVMC_, RbfNuSVMC_
and RbfCSVMC_).

.. _libsvm: http://www.csie.ntu.edu.tw/~cjlin/libsvm/
.. _Shogun: http://www.shogun-toolbox.org
.. _Wikipedia entry about SVM: http://en.wikipedia.org/wiki/Support_Vector_Machine
.. _libsvm.SVM: api/mvpa.clfs.libsvm.svm.SVM-class.html
.. _sg.SVM: api/mvpa.clfs.sg.svm.SVM-class.html
.. _LinearCSVMC: api/mvpa.clfs.svm.LinearCSVMC-class.html
.. _LinearNuSVMC: api/mvpa.clfs.svm.LinearNuSVMC-class.html
.. _RbfCSVMC: api/mvpa.clfs.svm.RbfCSVMC-class.html
.. _RbfNuSVMC: api/mvpa.clfs.svm.RbfNuSVMC-class.html


.. _metaclassifiers:

Meta-Classifiers
================

  *This section has been contributed by James M. Hughes.*

A meta-classifier is essentially a blanket term used to describe all classes
that appear functionally equivalent to a regular :class:`~mvpa.clfs.base.Classifier`, but which in
reality provide some extra amount of functionality on top of a normal
classifier.  Furthermore, they generally do not implement a :class:`~mvpa.clfs.base.Classifier`
*per se*, but rather take a :class:`~mvpa.clfs.base.Classifier` as input.  The methods then
typically called on a classifier (e.g., `train` or `predict`) can be
called on the meta-classifier, but will call the input classifier's routines,
before or after some other function that the meta-classifier provides.


Examples of Meta-Classifiers
----------------------------

At present, there are two primary meta-classifiers implemented in the PyMVPA
package, beneath which there are several specific options:

1. :class:`~mvpa.clfs.base.BoostedClassifier` -- these typically combine some aspect of the
   classifier's functionality with another component, such as prediction or data
   splitting

2. :class:`~mvpa.clfs.base.ProxyClassifier` -- these typically perform some action on the data/labels
   before classification is performed

Within these more general categories, specific classifiers are implemented.
For example, there are several :class:`~mvpa.clfs.base.BoostedClassifier` subclasses:

1. :class:`~mvpa.clfs.base.CombinedClassifier` -- combines predictions using a PredictionsCombiner_
   functor

2. :class:`~mvpa.clfs.base.MulticlassClassifier` -- performs multi-class classification by means of a
   list of :class:`~mvpa.clfs.base.BinaryClassifier` instances

3. :class:`~mvpa.clfs.base.SplitClassifier` -- combines a :class:`~mvpa.clfs.base.Classifier` and an arbitrary :class:`~mvpa.datasets.splitter.Splitter`

Furthermore, there are also several :class:`~mvpa.clfs.base.ProxyClassifier` subclasses:

1. :class:`~mvpa.clfs.base.BinaryClassifier` -- maps a set of labels into two categories, +1 and -1

2. :class:`~mvpa.clfs.base.MappedClassifier` -- uses a mapper on input data prior to training/testing

3. :class:`~mvpa.clfs.base.FeatureSelectionClassifier` -- performs some kind of FeatureSelection_ prior
   to training

.. _FeatureSelection: api/mvpa.featsel.base.FeatureSelection-class.html
.. _PredictionsCombiner: api/mvpa.clfs.base.PredictionsCombiner-class.html

Implementation Examples
-----------------------

Classifiers such as the :class:`~mvpa.clfs.base.FeatureSelectionClassifier` are particularly useful
because they simplify the process of selecting features and then using only
that subset of features to classify novel exemplars (the `predict` stage).
They become even more powerful when combined with :class:`~mvpa.clfs.base.SplitClassifier`, so that
even the task of withholding certain data points to create statistically valid
training and testing datasets is abstracted and wrapped up within a single
object (and, ultimately, very few method calls).  Consider the following code,
which can be found in `mvpa/clfs/warehouse.py`_:

.. _mvpa/clfs/warehouse.py: api/mvpa.clfs.warehouse-pysrc.html

  >>> from mvpa.clfs.base import SplitClassifier, FeatureSelectionClassifier
  >>> from mvpa.clfs.svm import LinearCSVMC
  >>> from mvpa.clfs.transerror import ConfusionBasedError
  >>> from mvpa.featsel.rfe import RFE
  >>> from mvpa.featsel.helpers import FractionTailSelector
  >>>
  >>> rfesvm_split = SplitClassifier(LinearCSVMC())
  >>> clf = \
  ...  FeatureSelectionClassifier(
  ...   clf = LinearCSVMC(),
  ...   # on features selected via RFE
  ...   feature_selection = RFE(
  ...       # based on sensitivity of a clf which does
  ...       # splitting internally
  ...       sensitivity_analyzer=rfesvm_split.getSensitivityAnalyzer(),
  ...       transfer_error=ConfusionBasedError(
  ...          rfesvm_split,
  ...          confusion_state="confusion"),
  ...          # and whose internal error we use
  ...       feature_selector=FractionTailSelector(
  ...                          0.2, mode='discard', tail='lower'),
  ...                          # remove 20% of features at each step
  ...       update_sensitivity=True),
  ...       # update sensitivity at each step
  ...   descr='LinSVM+RFE(splits_avg)' )

This analysis combines the :class:`~mvpa.clfs.base.FeatureSelectionClassifier` and the
:class:`~mvpa.clfs.base.SplitClassifier` to perform internal splitting of the data and then perform
FeatureSelection based on those splits.  Such analyses can be easily created
due to the straightforward way that classifier and meta-classifiers can be
combined.  Please refer to the relevant documentation sections for more
information about the specifics of each meta-classifier.



Retrainable Classifiers
=======================

Some classifiers have ability to provide quick (i.e in terms of performance)
re-training if they were previously trained, and only part of their
specification got changed. For instance, for kernel-based classifier
(e.g. GPR) it makes no sense to recompute kernel matrix, if only a classifier
(not kernel) parameter (e.g. ``sigma_noise``) was changed. Another similar
usecase: for :ref:`null-hypothesis statistical testing <statistical_testing>`
it might be needed to train classifier multiple times on a randomized set of labels.

Only classifiers which have ``retrainable`` in their ``_clf_internals`` are
capable of efficient retraining. To enable retraining, just provide
``retrainable=True`` to the constructor of the classifier. Internally
retrainable classifiers will try to deduce what was changed in the
specification of the classifier (e.g. training/testing datasets, parameters)
and act accordingly. To reduce training/prediction time even more, classifier
might directly be instructed with what aspects were changed. It must be
previously trained / predicted, so later on retrain_ and repredict_
methods could be called. repredict_ can be called only with the same data, for
which it was earlier predicted. See API doc for more information.

.. _retrain: api/mvpa.clfs.base.Classifier-class.html#retrain
.. _repredict: api/mvpa.clfs.base.Classifier-class.html#repredict

Implementation of efficient retraining is not straightforward, thus it is
strongly advised to

 * enable ``CHECK_RETRAIN`` debug target while developing the code for
   analysis. That might guard you against obvious misuses of retraining
   feature, as well as to spot bugs in the code
 * validate on a simple dataset that analysis code provides the same results
   if classifier was created retrainable or not




Classifiers "Warehouse"
=======================

To facilitate easy trial of different classifiers for any specific task,
Warehouse_ of classifiers clfs.warehouse.clfs was defined to create a sample
collection of some commonly used parameterizations of the classifiers present
in PyMVPA. Such collection can be queried by any set of known keywords/tags
with tags prefixed with ``!`` being excluded::

  >>> from mvpa.clfs.warehouse import clfs
  >>> tryme = clfs['multiclass', '!svm']

to simply sweep through classifiers which are capable of multiclass
classification and are not SVM based.

.. _Warehouse: api/mvpa.clfs.warehouse.Warehouse-class.html


