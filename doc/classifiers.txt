.. -*- mode: rst; fill-column: 78 -*-
.. ex: set sts=4 ts=4 sw=4 et tw=79:
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
  #
  #   See COPYING file distributed along with the PyMVPA package for the
  #   copyright and license terms.
  #
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###

.. _classifiers:

.. index:: classifier

***********
Classifiers
***********

PyMVPA includes a number of ready-to-use classifiers, which are described in
the following sections. All classifiers implement the same, very simple
interface. Each classifier object takes all relevant parameters as arguments to
its constructor. Once instantiated, the classifier object's
:meth:`~mvpa.clfs.base.Classifier.train` method can be called with some
dataset. This trains the classifier using *all* samples in the respective
dataset.

The major task for a classifier is to make predictions. Predictions are made by
calling the classifier's :meth:`~mvpa.clfs.base.Classifier.predict` method with
one or multiple data samples. :meth:`~mvpa.clfs.base.Classifier.predict`
operates on pure sample data and not datasets, as in some cases the true label
for a sample might be totally unknown.

This examples demonstrates the typical daily life of a classifier.

  >>> import numpy as N
  >>> from mvpa.clfs.knn import kNN
  >>> from mvpa.datasets import Dataset
  >>> training = Dataset(samples=N.array(
  ...                                N.arange(100),ndmin=2, dtype='float').T,
  ...                    labels=[0] * 50 + [1] * 50)
  >>> rand100 = N.random.rand(10)*100
  >>> validation = Dataset(samples=N.array(rand100, ndmin=2, dtype='float').T,
  ...                      labels=[ int(i>50) for i in rand100 ])
  >>> clf = kNN(k=10)
  >>> clf.train(training)
  >>> N.mean(clf.predict(training.samples) == training.labels)
  1.0
  >>> N.mean(clf.predict(validation.samples) == validation.labels)
  1.0

Two datasets with 100 and 10 samples each are generated. Both datasets only
have one feature and the associated label is 0 if the feature value is below
50 or 1 otherwise. The larger dataset contains all integers in the interval
(0,100) and is used to train the classifier. The smaller is used as a
validation dataset, to check whether the classifier learned something that
generalizes well across samples not included in the training dataset. In this
case the validation dataset consists of 10 random floating point values in the
interval (0,100).

The classifier in this example is a :class:`~mvpa.clfs.knn.kNN`
(k-Nearest-Neighbour) classifier that makes
use of the 10 nearest neighbours of a data sample to make its predictions
(k=10). One can see that after the training the classifier performs optimally
on the training dataset as well as on the validation data samples.

The choice of the classifier in the above example is more or less arbitrary.
Any classifier in PyMVPA could be used in place of kNN. This demonstrates
another useful feature of PyMVPA's classifiers. Due to the high-level
abstraction and the simple interface, almost all classifiers can be combined
with most algorithms in PyMVPA. This makes it very easy to test different
classifiers on some dataset (see Fig. 1).

.. image:: pics/classifier_comparison_plot.png
   :width: 12cm
   :alt: Classifier comparison

A comparison of the behavior of different classifiers (k-Nearest-Neighbour,
linear SVM, logistic regression, ridge regression and SVM with radial basis
function kernel) on a simple classification problem. The code to generate
these figure can be found in the `pylab_2d.py` example in the
:ref:`example_pylab_2d` section.


.. index:: states

Stateful objects
================

Before looking at the different classifiers in more detail, it is important to
mention another feature common to all of them. While their interface is simple,
classifiers are in no way limited to report only predictions. All classifiers
implement an additional interface: Objects of any class that are derived from
:class:`~mvpa.misc.state.ClassWithCollections` have attributes (we refer to
such attributes as state variables), which are conditionally computed and
stored by PyMVPA. Such conditional storage and access is handy if a variable of
interest might consume a lot of memory or needs intensive computation, and not
needed in most (or in some) of the use cases.

For instance, the :class:`~mvpa.clfs.base.Classifier` class defines the
`trained_labels` state variable, which just stores the unique labels for which
the classifier was trained. Since `trained_labels` stores meaningful
information only for a trained classifier, attempt to access
'clf.trained_labels' before training would result in an error,

 >>> from mvpa.misc.exceptions import UnknownStateError
 >>> try:
 ...     untrained_clf = kNN()
 ...     labels = untrained_clf.trained_labels
 ... except UnknownStateError:
 ...     "Does not work"
 'Does not work'

since the classifier has not seen the data yet and, thus, does not know the
labels. In other words, it is not yet in the state to know anything about the
labels. Any state variable can be enabled or disabled on per instance basis at
any time of the execution (see :class:`~mvpa.misc.state.ClassWithCollections`).

To continue the last example, each classifier, or more precisely every
stateful object, can be asked to report existing state-related attributes:

  >>> list_with_verbose_explanations = clf.states.listing

'clf.states' is an instance of :class:`~mvpa.misc.state.StateCollection` class
which is a container for all state variables of the given class. Although
values can be queried or set (if state is enabled) operating directly on the
stateful object

  >>> clf.trained_labels
  array([0, 1])

any other operation on the state (e.g. enabling, disabling) has to be carried
out through the `states` attribute.

  >>> print clf.states
  states{trained_dataset predicting_time*+ training_confusion predictions*+...}
  >>> clf.states.enable('values')
  >>> print clf.states
  states{trained_dataset predicting_time*+ training_confusion predictions*+...}
  >>> clf.states.disable('values')

A string representation of the state collection mentioned above lists
all state variables present accompanied with 2 markers: '+' for an
enabled state variable, and '*' for a variable that stores some value
(but might have been disabled already and, therefore, would have no
'+' and attempts to reassign it would result in no action).

.. TODO: Refactor

By default all classifiers provide state variables `values`,
`predictions`. The latter is simply the set of predictions that was returned
by the last call to the objects :meth:`~mvpa.clfs.base.Classifier.predict`
method. The former is heavily
classifier-specific. By convention the `values` key provides access to the
raw values that a classifier prediction is based on. Depending on the
classifier, this information might required significant resources when stored.
Therefore all states can be disabled or enabled (`states.disable()`,
`states.enable()`) and their current status can be queried like this:

  >>> clf.states.isActive('predictions')
  True
  >>> clf.states.isActive('values')
  False

States can be enabled or disabled during stateful object construction, if
`enable_states` or `disable_states` (or both) arguments, which store the list
of desired state variables names, passed to the object constructor. Keyword
'all' can be used to select all known states for that stateful object.


.. index:: error, classifier error, transfer error


.. _transfer_error:

Error Calculation
=================

The :class:`~mvpa.clfs.transerror.TransferError` class provides a convenient
way to determine the transfer error of a trained classifier on some validation
dataset, i.e. the accuracy of the classifier's predictions on a novel,
independent dataset. A :class:`~mvpa.clfs.transerror.TransferError` object is
instanciated by passing a classifier object to the constructor.  Optionally a
custom error function can be specified (see `errorfx` argument).

To compute the transfer error simply call the object with a validation dataset.
The computed error value is returned.
:class:`~mvpa.clfs.transerror.TransferError` also supports a state variable
`confusion` that contains the full confusion matrix of the predictions made on
the validation dataset. The confusion matrix is disabled by default.

If the :class:`~mvpa.clfs.transerror.TransferError` object is called with an
optional training dataset, the contained classifier is first training using
this dataset before predictions on the validation dataset are made.

  >>> from mvpa.clfs.transerror import TransferError
  >>> clf = kNN(k=10)
  >>> terr = TransferError(clf)
  >>> terr(validation, training )
  0.0



.. index:: cross-validation
.. _cross-validation:

Cross-validated Transfer Error
------------------------------

Often one is not only interested in a single transfer error on one validation
or test dataset, but on a cross-validated estimate of the transfer error. A
popular method is the so-called leave-one-out cross-validation.

The :class:`~mvpa.algorithms.cvtranserror.CrossValidatedTransferError` class
provides a simple way to compute such measure. It utilizes a
:class:`~mvpa.clfs.transerror.TransferError` object and a
:class:`~mvpa.datasets.splitter.Splitter`. When called with a
:class:`~mvpa.datasets.base.Dataset` the splitter generates splits of the
Dataset and the transfer error for all splits is computed by training on one of
the splitted datasets and making predictions on the other. By default the mean
of transfer errors is returned (but the actual `combiner` function is
customizable).

The following example shows the minimal code for a leave-one-out
cross-validation reusing the transfer error object from the previous example
and some :class:`~mvpa.datasets.base.Dataset` `data`.

  >>> # create some dataset
  >>> from mvpa.misc.data_generators import normalFeatureDataset
  >>> data = normalFeatureDataset(perlabel=50, nlabels=2,
  ...                             nfeatures=20, nonbogus_features=[3, 7],
  ...                             snr=3.0)
  >>> # now cross-validation
  >>> from mvpa.algorithms.cvtranserror import CrossValidatedTransferError
  >>> from mvpa.datasets.splitter import NFoldSplitter
  >>> cvterr = CrossValidatedTransferError(terr,
  ...                                      NFoldSplitter(cvtype=1))
  >>> error = cvterr(data)



Basic Supervised Learning Methods
=================================

PyMVPA provides a number of learning methods (i.e. classifiers or
regression algorithms) that can be plug into the various algorithms
that are also part of the framework. Most importantly they all can be
combined or enhanced with :ref:`metaclassifiers`.

.. index:: gaussian process regression, GPR


Gaussian Process Regression
---------------------------

:class:`~mvpa.clfs.gpr.GPR`
(`Wikipedia entry about gaussian process regression`_).

.. _Wikipedia entry about gaussian process regression: http://en.wikipedia.org/wiki/Gaussian_process_regression


.. index:: k-nearest-neighbour, kNN

k-Nearest-Neighbour
-------------------

The :class:`~mvpa.clfs.knn.kNN` classifier makes predictions based on the
labels of nearby samples.  It currently uses Euclidian distance to determine
the nearest neighbours, but future enhancements may include support for other
kernels.


.. index:: least angle regression, LARS

Least Angle Regression
----------------------

:class:`~mvpa.clfs.lars.LARS`
:ref:`Efron et al. (2004) <EHJ+04>`


.. index:: logistic regression, penalized logistic regression

Penalized Logistic Regression
-----------------------------

The penalized logistic regression (:class:`~mvpa.clfs.plr.PLR`) is similar to
the ridge in that it has a penalty term, however, it is trained to predict a
binary outcome by means of the logistic function (`Wikipedia entry about
logistic regression`_).

.. _Wikipedia entry about logistic regression: http://en.wikipedia.org/wiki/Logistic_regression


.. index:: ridge regression

Ridge Regression
----------------

Ridge regression (aka Tikhonov regularization) is a variant of a linear regression
(`Wikipedia entry about ridge regression`_).

The ridge regression classifier (:class:`~mvpa.clfs.ridge.RidgeReg`) performs a
simple linear regression with a penalty parameter to help avoid over-fitting.
The regression inserts an intercept term so that you do not have to center your
data.

.. _Wikipedia entry about ridge regression: http://en.wikipedia.org/wiki/Ridge_regression


.. index:: sparse multinomial logistic regression, SMLR

Sparse Multinomial Logistic Regression
--------------------------------------

Sparse Multinomial Logistic Regression (:class:`~mvpa.clfs.smlr.SMLR`;
:ref:`Krishnapuram et al., 2005 <KCF+05>`) is a fast multi-class classifier
that can easily deal with high-dimensional problems (`research paper about
SMLR`_).  PyMVPA includes two implementations: one in pure Python and a faster
one that makes use of a C extension for the performance critical pieces of the
code.

.. _research paper about SMLR: http://www.cs.duke.edu/~amink/publications/manuscripts/hartemink05.pami.pdf


.. index:: support vector machine, SVM

Support Vector Machines
-----------------------

Support vector machine (:ref:`Vapnik, 1995 <Vap95>`) classifiers (and
regressions) are popular
since they can deal with very high dimensional problems (`Wikipedia
entry about SVM`_), while maintaining reasonable generalization performance.

The support vector machine classes provide a family of classifiers by wrapping
libsvm_ and Shogun_ libraries, with corresponding base classes
:class:`~mvpa.clfs.svm.libsvm.SVM` and :class:`~mvpa.clfs.svm.sg.SVM`
accordingly. By default SVM class is bound to libsvm's implementation if such
is available (shogun otherwise).

While any SVM class provides a complete interface, the others child classes
make it easy to run some subset of standard classifiers, such as linear SVM,
with a default set of parameters (see :class:`~mvpa.clfs.svm.LinearCSVMC`,
:class:`~mvpa.clfs.svm.LinearNuSVMC`, :class:`~mvpa.clfs.svm.RbfNuSVMC` and
:class:`~mvpa.clfs.svm.RbfCSVMC`).

.. _libsvm: http://www.csie.ntu.edu.tw/~cjlin/libsvm/
.. _Shogun: http://www.shogun-toolbox.org
.. _Wikipedia entry about SVM: http://en.wikipedia.org/wiki/Support_Vector_Machine


.. _metaclassifiers:

Meta-Classifiers
================

  *This section has been contributed by James M. Hughes.*

A meta-classifier is essentially a blanket term used to describe all classes
that appear functionally equivalent to a regular :class:`~mvpa.clfs.base.Classifier`, but which in
reality provide some extra amount of functionality on top of a normal
classifier.  Furthermore, they generally do not implement a :class:`~mvpa.clfs.base.Classifier`
*per se*, but rather take a :class:`~mvpa.clfs.base.Classifier` as input.  The methods then
typically called on a classifier (e.g., `train` or `predict`) can be
called on the meta-classifier, but will call the input classifier's routines,
before or after some other function that the meta-classifier provides.


Examples of Meta-Classifiers
----------------------------

At present, there are two primary meta-classifiers implemented in the PyMVPA
package, beneath which there are several specific options:

1. :class:`~mvpa.clfs.base.BoostedClassifier` -- these typically combine some
    aspect of the classifier's functionality with another component, such as
    prediction or data splitting

2. :class:`~mvpa.clfs.base.ProxyClassifier` -- these typically perform some
    action on the data/labels before classification is performed

Within these more general categories, specific classifiers are implemented.
For example, there are several :class:`~mvpa.clfs.base.BoostedClassifier`
subclasses:

1. :class:`~mvpa.clfs.base.CombinedClassifier` -- combines predictions using a
    :class:`~mvpa.clfs.base.PredictionsCombiner` functor

2. :class:`~mvpa.clfs.base.MulticlassClassifier` -- performs multi-class
    classification by means of a list of
    :class:`~mvpa.clfs.base.BinaryClassifier` instances

3. :class:`~mvpa.clfs.base.SplitClassifier` -- combines a
    :class:`~mvpa.clfs.base.Classifier` and an arbitrary
    :class:`~mvpa.datasets.splitter.Splitter`

Furthermore, there are also several :class:`~mvpa.clfs.base.ProxyClassifier`
subclasses:

1. :class:`~mvpa.clfs.base.BinaryClassifier` -- maps a set of labels into two
    categories, +1 and -1

2. :class:`~mvpa.clfs.base.MappedClassifier` -- uses a mapper on input data
    prior to training/testing

3. :class:`~mvpa.clfs.base.FeatureSelectionClassifier` -- performs some kind of
    :class:`~mvpa.featsel.base.FeatureSelection` prior to training


Implementation Examples
-----------------------

Classifiers such as the :class:`~mvpa.clfs.base.FeatureSelectionClassifier` are
particularly useful because they simplify the process of selecting features and
then using only that subset of features to classify novel exemplars (the
`predict` stage).  They become even more powerful when combined with
:class:`~mvpa.clfs.base.SplitClassifier`, so that even the task of withholding
certain data points to create statistically valid training and testing datasets
is abstracted and wrapped up within a single object (and, ultimately, very few
method calls).  Consider the following code, which can be found in
`mvpa/clfs/warehouse.py`_:

.. _mvpa/clfs/warehouse.py: api/mvpa.clfs.warehouse-pysrc.html

  >>> from mvpa.clfs.base import SplitClassifier, FeatureSelectionClassifier
  >>> from mvpa.clfs.svm import LinearCSVMC
  >>> from mvpa.clfs.transerror import ConfusionBasedError
  >>> from mvpa.featsel.rfe import RFE
  >>> from mvpa.featsel.helpers import FractionTailSelector
  >>>
  >>> rfesvm_split = SplitClassifier(LinearCSVMC())
  >>> clf = \
  ...  FeatureSelectionClassifier(
  ...   clf = LinearCSVMC(),
  ...   # on features selected via RFE
  ...   feature_selection = RFE(
  ...       # based on sensitivity of a clf which does
  ...       # splitting internally
  ...       sensitivity_analyzer=rfesvm_split.getSensitivityAnalyzer(),
  ...       transfer_error=ConfusionBasedError(
  ...          rfesvm_split,
  ...          confusion_state="confusion"),
  ...          # and whose internal error we use
  ...       feature_selector=FractionTailSelector(
  ...                          0.2, mode='discard', tail='lower'),
  ...                          # remove 20% of features at each step
  ...       update_sensitivity=True),
  ...       # update sensitivity at each step
  ...   descr='LinSVM+RFE(splits_avg)' )

This analysis combines the :class:`~mvpa.clfs.base.FeatureSelectionClassifier`
and the :class:`~mvpa.clfs.base.SplitClassifier` to perform internal splitting
of the data and then perform FeatureSelection based on those splits.  Such
analyses can be easily created due to the straightforward way that classifier
and meta-classifiers can be combined.  Please refer to the relevant
documentation sections for more information about the specifics of each
meta-classifier.



Retrainable Classifiers
=======================

Some classifiers have ability to provide quick (i.e in terms of performance)
re-training if they were previously trained, and only part of their
specification got changed. For instance, for kernel-based classifier (e.g. GPR)
it makes no sense to recompute kernel matrix, if only a classifier (not kernel)
parameter (e.g. ``sigma_noise``) was changed. Another similar usecase: for
:ref:`null-hypothesis statistical testing <example_permutation_test>` it might be
needed to train classifier multiple times on a randomized set of labels.

Only classifiers which have ``retrainable`` in their ``_clf_internals`` are
capable of efficient retraining. To enable retraining, just provide
``retrainable=True`` to the constructor of the classifier. Internally
retrainable classifiers will try to deduce what was changed in the
specification of the classifier (e.g. training/testing datasets, parameters)
and act accordingly. To reduce training/prediction time even more, classifier
might directly be instructed with what aspects were changed. It must be
previously trained / predicted, so later on
:meth:`~mvpa.clfs.base.Classifier.retrain` and
:meth:`~mvpa.clfs.base.Classifier.repredict` methods could be called.
:meth:`~mvpa.clfs.base.Classifier.repredict` can be called only with the same
data, for which it was earlier predicted. See API doc for more information.

Implementation of efficient retraining is not straightforward, thus it is
strongly advised to

 * enable ``CHECK_RETRAIN`` debug target while developing the code for
   analysis. That might guard you against obvious misuses of retraining
   feature, as well as to spot bugs in the code
 * validate on a simple dataset that analysis code provides the same results
   if classifier was created retrainable or not




Classifiers "Warehouse"
=======================

To facilitate easy trial of different classifiers for any specific task,
:class:`~mvpa.clfs.warehouse.Warehouse` of classifiers clfs.warehouse.clfs was
defined to create a sample collection of some commonly used parameterizations
of the classifiers present in PyMVPA. Such collection can be queried by any set
of known keywords/tags with tags prefixed with ``!`` being excluded::

  >>> from mvpa.clfs.warehouse import clfs
  >>> tryme = clfs['multiclass', '!svm']

to simply sweep through classifiers which are capable of multiclass
classification and are not SVM based.
