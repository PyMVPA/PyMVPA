.. -*- mode: rst -*-
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###
  #
  #   See COPYING file distributed along with the PyMVPA package for the
  #   copyright and license terms.
  #
  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###

PyMVPA Manual
=============

:Authors:
  Michael Hanke <michael.hanke@gmail.com>;
  Yaroslav O. Halchenko <debian@onerussian.com>
:Contact:  pkg-exppsy-pymvpa@lists.alioth.debian.org
:Homepage: http://pkg-exppsy.alioth.debian.org/pymvpa/
:Revision: 0.0.1

.. Please add yourself to the list of authors if you contribute something
   to this manual.

.. contents::
.. sectnum::



Introduction
------------

PyMVPA stands for *Multivariate Pattern Analysis* in Python_.

Prerequisites
~~~~~~~~~~~~~
 * Basic Python experiences (if not easy to get with Python tutorials).
 * For efficiency:

   - prior experience with NumPy and/or SciPy.
   - basic understanding of the concepts(s) of machine learning.


Conventions
~~~~~~~~~~~
NumPy package will by used as N throughout this manual.

  >>> import numpy as N

* Note how to cite it.


A Bit of History
~~~~~~~~~~~~~~~~

The roots of PyMVPA date back to early 2005. At that time it was a C++ library
(no Python_ yet) developed by Michael Hanke and Sebastian Kr√ºger with the
purpose to easily apply artificial neural networks to pattern recognition
problems.

During a visit to `Princeton University`_ in spring 2005 Michael Hanke
was introduced to the `MVPA toolbox`_ for `Matlab
<http://buchholz.hs-bremen.de/aes/aes_matlab.gif>`_. This toolbox was
and is mainly developed by `Greg Detre`_ and had several advantages
over a C++ library. Most importantly it was easier to use. While a
user of a C++ library is forced to write a significant amount of
front-end code, users of the MVPA toolbox could simply load their data
and start analyzing it. Besides that the MVPA toolbox offered a number
of algorithms that were not implmented in the C++ library.

.. _Princeton University: http://www.princeton.edu
.. _MVPA toolbox: http://www.csbmb.princeton.edu/mvpa/
.. _Greg Detre: http://www.gregdetre.co.uk

However, writing a Matlab toolbox implies some disadvantages that also
apply to the MVPA toolbox. While users in general benefit from the powers
of Matlab, they are at the same time bound to the goodwill of a commercial
company. That this is indeed a problem becomes obvious when one consideres the
time when the vendor of Matlab was not willing to support the Mac platform.
Therefore even if the MVPA toolbox is `GPL-licensed`_ it cannot fully benefit
from the enourmous advantages of the free-software development model
environment (free as in free speech, not only free beer).

.. _GPL-licensed: http://www.gnu.org/copyleft/gpl.html

Under this impression Michael thought that a successor of the C++ library
should remain truely free-software, remain fully object-oriented (in contrast
to the MVPA toolbox), but should be at least as easy to use and extensible
as the MVPA toolbox.

After evaluating some possibilities Michael decided that `Python`_ is the
most promissing candidate that was fully capable to fulfil the intended
development goal. Python is a very powerful language that magically combines
the possibility to write really fast code and a simplicity that allows to
learn the basic concepts within a few days.

.. _Python: http://www.python.org

One of the major advantages of Python is the availablity of a huge amount of
so called *modules*. Modules can include extensions written in a hard-core
language like C and therefore allow to incorporate high-performance code
without having to leave the Python environment. Additionally some Python
modules even provide links to other toolkits. For example `RPy`_ allows to use
the full functionality of R_ from inside Python. Even Matlab can be used via
some Python modules (see PyMatlab_ for an example).

.. _RPy: http://rpy.sourceforge.net/
.. _R: http://www.r-project.org
.. _PyMatlab: http://code.google.com/p/pymatlab/

After the decision for Python was made, Michael started development with a
simple k-Nearest-Neighbour classifier and a cross-validation class. Using
the mighty NumPy_ package made it easy to support data of any dimensionality.
Therefore PyMVPA can easily be used with 4d fMRI dataset, but equally well
with EEG data (3d) or even non-neuroimaging datasets.

.. _NumPy: http://numpy.scipy.org/

By September 2007 PyMVPA included support for reading and writing datasets
from and to the `NIfTI format`_, kNN and Support Vector Machine classifiers,
as well as several analysis algorithms (e.g. searchlight and incremental
feature search).

.. _NIfTI format: http://nifti.nimh.nih.gov/

During another visit in Princeton in October 2007 Michael met with `Yaroslav
Halchenko`_ and `Per B. Sederberg`_. That incident and the following
discussions and hacking sessions of Michael and Yaroslav lead to a major
refactoring of the PyMVPA codebase, making it much more flexible/extensible,
faster and easier as it has ever been before.

.. _Yaroslav Halchenko: http://www.onerussian.com/
.. _Per B. Sederberg: http://www.princeton.edu/~persed/


Credits
~~~~~~~

.. Please add some notes when you think that you should give credits to someone
   that enables or motivates you to work on PyMVPA ;-)



Overview
--------

The PyMVPA package consists of three major parts: `Data handling`_,
Classifiers_ and Algorithms_ operating on datasets and classifiers.
In the following sections the basic concept of all three parts will be
described and examples using certain parts of the PyMVPA package will be
given.



Data Handling
-------------

The foundation of PyMVPA's data handling is the `Dataset` class. Basically,
this class stores data samples, sample attributes and dataset attributes, where
sample attributes assign a value to each data sample and dataset attributes are
additional information or functionality that applies to the whole dataset.

Most likely the `Dataset` class will not be used directly, but through one
of the derived classes. However, it is perfectly possible to use it directly.
In the simplest case a dataset can be constructed by specifying some
data samples and the corresponding class labels.

  >>> from mvpa.datasets.dataset import Dataset
  >>> data = Dataset(samples=N.random.normal(size=(10,5)), labels=1)
  >>> data
  Dataset / float64 10 x 5, uniq: 1 labels, 10 chunks

The above example creates a dataset with 10 samples and 5 features each. The
values of all features stem from normally distributed random noise. The class
label '1' is assigned to all samples. Instead of a single scalar value `labels`
can also be a sequence with individual labels for each data sample. In this
case the length of this sequence has to match the number of samples.

Interestingly the dataset object tells us about 10 `chunks`. In PyMVPA chunks
are used to group subsets of data samples. However, if no grouping information
is provided all data samples are assumed to be in their own group, hence no
sample grouping is performed.

Both `labels` and `chunks` are so called *sample attributes*. All sample
attributes are stored in sequence-type containers consisting of one value per
sample. These containers can be accessed by properties with the same as the
attribute:

  >>> data.labels
  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
  >>> data.chunks
  array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

The *data samples* itself are stored as a two-dimensional matrix where each
row vector is a `sample` and each column vector contains the values of a
`feature` across all `samples`. The `Dataset` class provides access to the
samples matrix via the `samples` property.

  >>> data.samples.shape
  (10,5)

The `Dataset` class itself can only deal with 2d sample matrices. However,
PyMVPA provides a very easy way to deal with data where each data sample is
more than a 1d vector: `Data Mapping`_


Data Mapping
~~~~~~~~~~~~
It was already mentioned that the `Dataset` class cannot deal with data samples
that are more than simple vectors. This could be a problem in cases where the
data has a higher dimensionality, e.g. functional brain-imaging data where
each data sample is typically a three-dimensional volume.

One approach to deal with this situation would be to concatenate the whole
volume into a 1d vector. While this would work in certain cases there is
definitely information lost. Especially for brain-imaging data one would most
likely want keep information about neighbourhood and distances between data
sample elements.

In PyMVPA this is done by mappers that transform data samples from their
original *dataspace* into the so-called *features space*. In the above
neuro-imaging example the *dataspace* is three-dimensional and the
*feature space* always refers to the 2d `samples x features` representation
that is required by the `Dataset` class. In the context of mappers the
dataspace is sometimes also refered to as *in-space* while the feature space
is labeled as *out-space*.

The task of a mapper besides transforming samples into 1d vectors is to retain
as much information of the dataspace as possible. Some mappers provide
information about dataspace metrics and feature neighbourhood, but all mappers
are able to do reverse mapping from feature space into the original dataspace.

Usually one does not have to deal with mappers directly. PyMVPA provides some
convenience subclasses of `Dataset` the automatically perform the necessary
mapping operations internally. 

.. Explain `MaskedDataset` -- or better think about it again as Yarik doesn't
   like it and he might remove it when Michael is not watching ;-)
   But serious, what is best to put that early in the manual? Maybe starting
   with NiftiDataset is even better and later explain the concept of
   `MappedDataset` -- comments?


Classifiers
-----------

.. First generic interface of all classifiers in PyMVPA. Point to the special
   case of multi-class classification and how to deal with it. Finally describe
   features of all available classifiers.


k-Nearest-Neighbour
~~~~~~~~~~~~~~~~~~~


Support Vector Machines
~~~~~~~~~~~~~~~~~~~~~~~


Logistic Regression
~~~~~~~~~~~~~~~~~~~


Algorithms
----------

.. Again general overview first. What is a `SensitivityAnalyzer`, what is the
   difference between a `FeatureSelection` and an `ElementSelector`.
   Finally more detailed note and references for each larger algorithm.

.. Explain the concept of having algorithm object instances that configure with
   parameters upon creation and can be used multiple times by calling them with
   datasets. Also attache explaination of PyMVPA object `states` at that point.

.. Point to the difference of `DataMeasure` and `SensitivityAnalyzer`. The
   former computes some value given a dataset (might be scalar or something
   else), whereas that latter computes a 1d map (sensitivity -> features),
   where each value assigns a quantification of the amount of available
   information in that feature.


Searchlight
~~~~~~~~~~~
.. Mention the fact that it also is a special `SensitivityAnalyzer`


Recursive Feature Elimination
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Incremental Feature Search
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. What are the practical differences (besides speed) between RFE and IFS?


Installation
------------

.. Point to source and binary distribution. Preach idea of free software.
   Step by step guide to install it on difficult systems like Windows.

.. Don't forget to mention that the only reasonable way is to use this piece
   of software (like every other piece) is under Debian! Also mention that
   Ubuntu is no excuse ;-)


Frequently Asked Questions
--------------------------

.. We probably need them once we have more than two users.



License
-------

The PyMVPA package, including all examples, code snippets and attached
documentation is covered by the MIT license.

::

  The MIT License

  Copyright (c) 2006-2007 Michael Hanke
                     2007 Yaroslav Halchenko

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
  THE SOFTWARE.
