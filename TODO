#emacs: -*- mode: python-mode; py-indent-offset: 4; indent-tabs-mode: nil -*-
#ex: set sts=4 ts=4 sw=4 et:

* selected_ids -> implement via MaskMapper? 
  yoh: it might be preferable to manipulate/expose MaskMapper instead
   of plain list of selected_ids within FeatureSelection classes
* unify naming of working/testing 
    transerror.py for instance uses testdata/trainingdata
    rfe.py dataset, testdataset
* ConfusionBasedError -> InternalError ?

* Think about how to deal with Transformers to serve them with
   basic_analyzers... May be transformer can be a an argument for any
   analyzer! Ha! Indeed... may be later


* Renaming of the modules
  transerror.py -> errors.py

* SVM: getSV and getSVCoef return very 'packed' presentation
   whenever classifier is multiclass. Thus they have to be unpacked
   before proper use (unless it is simply a binary classifier).

* Regression tests: for instance using sample dataset which we have
   already, run doc/examples/searchlight.py and store output to
   validate against. Probably the best would be to create a regression
   test suite within unit tests which would load the dataset and run
   various algorithms on it a verify the results against previousely
   obtained (and dumped to the disk)

* Agree on how to describe parameters to functions. Describe in
 NOTES.coding.

* feature_selector -- may be we should return a tuple
  (selected_ids, discarded_ids)?
  Michael: Is there any use case for that? ElementSelector can 'select' and
           'discard' already. DO we need both simultaneously?

* Basic documentation: Examples (more is better) describing various use cases
   (everything in the cncre should be done in examples)

*  Non-linear SVM RFE

*  ParameterOptimizer
   (might be also OptimizedClassifier which uses parameterOptimizer
    internally but as the result there is a classifier which
    automatically optimizes its parameters. It is close in idea to
    classifier based on RFE)

* provide for Dataset -- Dataset.__featattr which has attributes for
   features similar to __dsattr way.

 in  --> data         -> dataShape
 out --> features     ->

* Let's forget about the 'callables' interface of the various algorithms for
  two reasons:

  1) Hardly any object really implements it.
  2) Whatever one wants to do with callables should be doable with state
     variables. If some information is missing in the state, this is a bug on
     its own. Only in rare cases where the amount of information to be stored
     is really huge this has some disadvantages. But given the ugliness of
     'callables' maybe it is worth risking it.

  Comments?
