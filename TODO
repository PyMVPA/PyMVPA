* Add support for topology support for stuff other than dense mask matrices,
  e.g. meshes.
* Hide libsvm interface from user and provide a unique classifier for linear
  SVM.
* (features selected on all folds)/(features selected on any fold)

* Regression tests: for instance using sample dataset which we have
   already, run doc/examples/searchlight.py and store output to
   validate against. Probably the best would be to create a regression
   test suite within unit tests which would load the dataset and run
   various algorithms on it a verify the results against previousely
   obtained (and dumped to the disk)

* Implement a better __deepcopy__ for maskmapper that does not call
  _initMask(), but copies the whole state. This has to be done because
  shallow copies of the mapping mask will results in modifications of the
  source mapper.

* confirm with Michael and refactor:

* for yarik: 

  DONE: verify on 'bad' searchlight that we get the same 'wrong' results and
   compare the performance time-wise. results stay the same. to get to
   the same speed had to disable all deepcopying within select{Features,Samples}

  DONE: refactor code so getNSamplesPerAttr returns a dictionary (not just numbers)

  maskmapper -- profile selectOut and see if alternative
   implementation will be faster. Also add removeOut  

  maskmapper -- selectFeatures

Further PLAN:
-------------
  a bit of profiling to gain at least on searchlight example

  RFE   -- more concrete/unified and more talking

  Features work:
   Algorithms:
   -- CrossValidation (provide 0-hypothesis testing)
   -- RFE

   Sensitivities:
   -- Linear SVM sensitivity
   -- Searchlight
   ? Anova? GLM?

   Classifiers:
   -- Linear and Non-linear SVM
   -- kNN
   -- RFE-based classifier (takes arbitrary classifier and
   sensitivityAnalyzer and deduces the subset of features with max
   generalization to spit out the classifier)
   -- BoostedClassifier (takes arbitrary subsets of features to
   combine by voting/whatever multiple classifiers)

  Basic documentation:
   * Generic API description
   * Examples (more is better) describing various use cases
   (everything in the cncre should be done in examples)

  and finally release 0.1.0 version! ;-)
  --------------------------------------
  WORK ON CNCRE! If we get far and informative -- enough, if not --
   proceed further:

  0-hypothesis testing to get better generalization estimate via MC
   bootstraps of the data?

  GenericSensitivityAnalyzers (AKA NoisePertubation) -- just computes
   sensitivity by altering features for any classifier.

  Non-linear SVM RFE

  ParameterOptimizer
   (might be also OptimizedClassifier which uses parameterOptimizer
    internally but as the result there is a classifier which
    automatically optimizes its parameters. It is close in idea to
    classifier based on RFE)

  World domination! 0.2.0 version
  --------------------------------------

* For anyone (possible useful ideas):

  provide for Dataset -- Dataset.__featattr which has attributes for
   features similar to __dsattr way.

 maskmapper:
  dsshape -> inShape
  nfeatures -> outSize

 in  --> data         -> dataShape
 out --> features     -> 

