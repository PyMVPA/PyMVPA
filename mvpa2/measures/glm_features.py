# emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode: nil -*-
# vi: set ft=python sts=4 ts=4 sw=4 et:
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##
#
#   See COPYING file distributed along with the PyMVPA package for the
#   copyright and license terms.
#
### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ##
"""Extract features for MVPA using univariate GLM modeling
"""

__docformat__ = 'restructuredtext'

import numpy as np

from mvpa2.base import externals

## # do conditional to be able to build module reference
## if externals.exists('statsmodels', raise_=True):
##     import statsmodels.api as sm

from mvpa2.measures.base import FeaturewiseMeasure
from mvpa2.datasets.base import Dataset

def fsl_design_to_evs(fsf_filename):
    """Load FSL design and spit out description of EVs and other regressors
    used in the original analysis.  Each EV should also carry HRF definition
    so that our model then should be 100% match to the one generated by FSL
    """
    pass # TODO
    """should we carry HRFs or should we have a separate structure describing
    ev -> HRF, w or without derivative?"""

def bunch_to_evs(b):
    evs = dict([(c, {'onsets': o, 'durations': d})
                for c, o, d in zip(b.conditions, b.onsets, b.durations)])
    if hasattr(b, 'regressor_names'):
        regressors = dict([(r, v) for r, v in zip(b.regressor_names, b.regressors)])
    else:
        regressors = None
    assert(not hasattr(b, 'tmod') or not b.get('tmod', None))
    assert(not hasattr(b, 'pmod') or not b.get('pmod', None))
    return evs, regressors


def regroup_conditions(evs, groups):
    """Reassign some EVs into others identified by new group names
    """
    out = evs.copy()
    for g, members in groups.iteritems():
        out[g] = sum([out.pop(m) for m in members], [])
    return out


class HRFEstimator(FeaturewiseMeasure):
    """

    Given evs: familiar, unfamiliar, self, oddball, motor
    we would like to estimate separate HRF per each group

    output would be 3D dataset which would have
    group x voxel x temporal_offset

    or may be group x voxel  object nd-array of sympy style generators?

    estimators to implement/interface

    - hrf_estimation:  use hrf_estimation library to estimate HRF per each
      voxel while events within condition share the same HRF.

     #1
      For that we would need to iterate hrf_estimation for few iterations
      while choosing EV to optimize, while placing others into "drifts".

      Order should not matter -- we will do
      1st step:  all share HRF
      2- step:
        for each EV place others into 'drifts' while taking HRF for them from
        previous step
     #2
      or may be it would be possible to fake extended HRF which would contain
      blocks of FIR for each "group"?

    - FIR:
      just deduce FIR per each voxel/EV using GLM

      pros: should be a stable HRF estimate
      cons: since different trial subtypes might have differing amplitude
            of responses and even shape -- such a mean FIR might be quite
            suboptimal

    - Turner et al: they actually do not estimate HRF for a voxel per se.

      Every EV/voxel would get its own HRF as the output of their
      feature extraction

      pros: account for HRF variability across trials???
      cons: noisier and more features to characterize each trial

    """

    # We might well want to train separately
    #is_trained = True

    def __init__(self, evs, TR, ev_groups=None,
                 estimator='hrf_estimation',
                 **kwargs):
        """
        Parameters
        ----------
        evs : dict of EVs
           dict of explanatory variables definitions
            each value would have
             onsets, (in sec)
             durations, (optional, assume 1 if none)
#             ?hrf, callable which given time points produces HRF kernel for convolution
        ## ev_groups : dict, optional
        ##   In the model, group EVs for HRF shape estimation first, before taking
        ##   them apart.  If None, then assume that all conditions are on their own
        """
        FeaturewiseMeasure.__init__(self, **kwargs)
        self._evs = evs
        self._TR = TR
        #self._ev_groups = ev_groups

    def _train(self, dataset):
        ntimepoints = len(dataset)
        # for hrf_estimator, we would need to generate the design matrix
        # which we would later expand for FIRs
        
        # in case of later 
